{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "blind-burner",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import linear_model\n",
    "from sklearn.datasets import load_boston\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn import preprocessing \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import sys\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "fifteen-consultation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data set\n",
    "data = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "equal-israel",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_data = pd.DataFrame(data.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "lovely-hearts",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.613524</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>12.653063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.601545</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>7.141062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>375.377500</td>\n",
       "      <td>6.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.256510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>391.440000</td>\n",
       "      <td>11.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.677083</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.225000</td>\n",
       "      <td>16.955000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
       "std      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
       "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
       "75%      3.677083   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "               6           7           8           9           10          11  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
       "std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
       "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
       "50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
       "75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "               12  \n",
       "count  506.000000  \n",
       "mean    12.653063  \n",
       "std      7.141062  \n",
       "min      1.730000  \n",
       "25%      6.950000  \n",
       "50%     11.360000  \n",
       "75%     16.955000  \n",
       "max     37.970000  "
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_data.describe() # no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "moral-ridge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  \n",
       "0       15.3  396.90   4.98  \n",
       "1       17.8  396.90   9.14  \n",
       "2       17.8  392.83   4.03  \n",
       "3       18.7  394.63   2.94  \n",
       "4       18.7  396.90   5.33  \n",
       "..       ...     ...    ...  \n",
       "501     21.0  391.99   9.67  \n",
       "502     21.0  396.90   9.08  \n",
       "503     21.0  396.90   5.64  \n",
       "504     21.0  393.45   6.48  \n",
       "505     21.0  396.90   7.88  \n",
       "\n",
       "[506 rows x 13 columns]"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_data.columns = data.feature_names\n",
    "boston_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "settled-airline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  price  \n",
       "0       15.3  396.90   4.98   24.0  \n",
       "1       17.8  396.90   9.14   21.6  \n",
       "2       17.8  392.83   4.03   34.7  \n",
       "3       18.7  394.63   2.94   33.4  \n",
       "4       18.7  396.90   5.33   36.2  \n",
       "..       ...     ...    ...    ...  \n",
       "501     21.0  391.99   9.67   22.4  \n",
       "502     21.0  396.90   9.08   20.6  \n",
       "503     21.0  396.90   5.64   23.9  \n",
       "504     21.0  393.45   6.48   22.0  \n",
       "505     21.0  396.90   7.88   11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_data['price'] = data.target\n",
    "boston_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "demonstrated-disco",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CRIM',\n",
       " 'ZN',\n",
       " 'INDUS',\n",
       " 'CHAS',\n",
       " 'NOX',\n",
       " 'RM',\n",
       " 'AGE',\n",
       " 'DIS',\n",
       " 'RAD',\n",
       " 'TAX',\n",
       " 'PTRATIO',\n",
       " 'B',\n",
       " 'LSTAT']"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = linear_model.LinearRegression()\n",
    "features = [col for col in boston_data.columns if not col == 'price' ]\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "herbal-feeding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = boston_data[features].to_numpy()\n",
    "X = std_scaler.fit_transform(X)\n",
    "reg.fit(X,boston_data.price)\n",
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "hearing-guide",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[22.532806324110677,\n",
       " -0.9281460643011966,\n",
       " 1.0815686278223822,\n",
       " 0.14089999690428612,\n",
       " 0.6817397247777939,\n",
       " -2.0567182660052157,\n",
       " 2.674230165239318,\n",
       " 0.01946607165704728,\n",
       " -3.104044258086441,\n",
       " 2.662217642473626,\n",
       " -2.0767816838433766,\n",
       " -2.0606066589067593,\n",
       " 0.8492684177053297,\n",
       " -3.7436271264671093]"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_betas = []\n",
    "reg_betas.append(reg.intercept_)\n",
    "reg_betas.extend(reg.coef_)\n",
    "reg_betas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "suspected-receiver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.532806324110677"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "retired-rugby",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7406426641094095"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get r^2 score for the model\n",
    "r2_score(boston_data.price,reg.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "clean-blast",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a summary of the model using OLS from statsmodels\n",
    "std_scaler = preprocessing.StandardScaler()\n",
    "\n",
    "#X  = sm.add_constant(X)\n",
    "y = boston_data.price\n",
    "model = sm.OLS(y,sm.add_constant(X))\n",
    "results=model.fit()\n",
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "incomplete-franklin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>price</td>      <th>  R-squared:         </th> <td>   0.741</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.734</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   108.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 07 Sep 2021</td> <th>  Prob (F-statistic):</th> <td>6.72e-135</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>01:50:20</td>     <th>  Log-Likelihood:    </th> <td> -1498.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   506</td>      <th>  AIC:               </th> <td>   3026.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   492</td>      <th>  BIC:               </th> <td>   3085.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    13</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   22.5328</td> <td>    0.211</td> <td>  106.814</td> <td> 0.000</td> <td>   22.118</td> <td>   22.947</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -0.9281</td> <td>    0.282</td> <td>   -3.287</td> <td> 0.001</td> <td>   -1.483</td> <td>   -0.373</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    1.0816</td> <td>    0.320</td> <td>    3.382</td> <td> 0.001</td> <td>    0.453</td> <td>    1.710</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.1409</td> <td>    0.421</td> <td>    0.334</td> <td> 0.738</td> <td>   -0.687</td> <td>    0.969</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.6817</td> <td>    0.219</td> <td>    3.118</td> <td> 0.002</td> <td>    0.252</td> <td>    1.111</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>   -2.0567</td> <td>    0.442</td> <td>   -4.651</td> <td> 0.000</td> <td>   -2.926</td> <td>   -1.188</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    2.6742</td> <td>    0.293</td> <td>    9.116</td> <td> 0.000</td> <td>    2.098</td> <td>    3.251</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.0195</td> <td>    0.371</td> <td>    0.052</td> <td> 0.958</td> <td>   -0.710</td> <td>    0.749</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>   -3.1040</td> <td>    0.420</td> <td>   -7.398</td> <td> 0.000</td> <td>   -3.928</td> <td>   -2.280</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    2.6622</td> <td>    0.577</td> <td>    4.613</td> <td> 0.000</td> <td>    1.528</td> <td>    3.796</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -2.0768</td> <td>    0.633</td> <td>   -3.280</td> <td> 0.001</td> <td>   -3.321</td> <td>   -0.833</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>   -2.0606</td> <td>    0.283</td> <td>   -7.283</td> <td> 0.000</td> <td>   -2.617</td> <td>   -1.505</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>    0.8493</td> <td>    0.245</td> <td>    3.467</td> <td> 0.001</td> <td>    0.368</td> <td>    1.331</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>   -3.7436</td> <td>    0.362</td> <td>  -10.347</td> <td> 0.000</td> <td>   -4.454</td> <td>   -3.033</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>178.041</td> <th>  Durbin-Watson:     </th> <td>   1.078</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 783.126</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.521</td>  <th>  Prob(JB):          </th> <td>8.84e-171</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.281</td>  <th>  Cond. No.          </th> <td>    9.82</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  price   R-squared:                       0.741\n",
       "Model:                            OLS   Adj. R-squared:                  0.734\n",
       "Method:                 Least Squares   F-statistic:                     108.1\n",
       "Date:                Tue, 07 Sep 2021   Prob (F-statistic):          6.72e-135\n",
       "Time:                        01:50:20   Log-Likelihood:                -1498.8\n",
       "No. Observations:                 506   AIC:                             3026.\n",
       "Df Residuals:                     492   BIC:                             3085.\n",
       "Df Model:                          13                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         22.5328      0.211    106.814      0.000      22.118      22.947\n",
       "x1            -0.9281      0.282     -3.287      0.001      -1.483      -0.373\n",
       "x2             1.0816      0.320      3.382      0.001       0.453       1.710\n",
       "x3             0.1409      0.421      0.334      0.738      -0.687       0.969\n",
       "x4             0.6817      0.219      3.118      0.002       0.252       1.111\n",
       "x5            -2.0567      0.442     -4.651      0.000      -2.926      -1.188\n",
       "x6             2.6742      0.293      9.116      0.000       2.098       3.251\n",
       "x7             0.0195      0.371      0.052      0.958      -0.710       0.749\n",
       "x8            -3.1040      0.420     -7.398      0.000      -3.928      -2.280\n",
       "x9             2.6622      0.577      4.613      0.000       1.528       3.796\n",
       "x10           -2.0768      0.633     -3.280      0.001      -3.321      -0.833\n",
       "x11           -2.0606      0.283     -7.283      0.000      -2.617      -1.505\n",
       "x12            0.8493      0.245      3.467      0.001       0.368       1.331\n",
       "x13           -3.7436      0.362    -10.347      0.000      -4.454      -3.033\n",
       "==============================================================================\n",
       "Omnibus:                      178.041   Durbin-Watson:                   1.078\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              783.126\n",
       "Skew:                           1.521   Prob(JB):                    8.84e-171\n",
       "Kurtosis:                       8.281   Cond. No.                         9.82\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protecting-minimum",
   "metadata": {},
   "source": [
    "## personal class representing multiple linear regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "endless-engineer",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultipleLinearRegression:\n",
    "    def __init__(self,X,y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.n = np.size(self.y)\n",
    "        self.beta = self.normalEq()\n",
    "        self.y_mean = (sum(y)/self.n)*np.ones(np.shape(self.y))\n",
    "        \n",
    "    def normalEq (self):\n",
    "        return (np.linalg.inv(self.X.T@self.X)@self.X.T@self.y)\n",
    "    def getbeta (self):\n",
    "        return self.beta\n",
    "    def predict (self,X,b):\n",
    "        return X@self.beta\n",
    "    def getSSR (self,b):\n",
    "        return (self.predict(self.X,b)-self.y_mean).T@(self.predict(self.X,b)-self.y_mean)\n",
    "    def getSST (self):\n",
    "        return (self.y-self.y_mean).T@(self.y-self.y_mean)\n",
    "    def getRSquared (self,b):\n",
    "        return self.getSSR(b)/self.getSST()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "improved-adjustment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model = MultipleLinearRegression(sm.add_constant(X),y)\n",
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "danish-probability",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.25328063e+01, -9.28146064e-01,  1.08156863e+00,  1.40899997e-01,\n",
       "        6.81739725e-01, -2.05671827e+00,  2.67423017e+00,  1.94660717e-02,\n",
       "       -3.10404426e+00,  2.66221764e+00, -2.07678168e+00, -2.06060666e+00,\n",
       "        8.49268418e-01, -3.74362713e+00])"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.getbeta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "arbitrary-development",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7406426641094074"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.getRSquared(my_model.beta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rising-gather",
   "metadata": {},
   "source": [
    "## gradient descent function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "adequate-manitoba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X,y,learning_rate=0.1,tol = 0.000000001,stop_cond = \"norm_beta\"):\n",
    "    X = sm.add_constant(X)\n",
    "    (n,p) = np.shape(X)\n",
    "    beta = np.random.uniform(-10.0, 10.0, p)\n",
    "    last_beta = beta.copy()\n",
    "    num_iteration = 0\n",
    "    \n",
    "    while(True):\n",
    "        errors = np.subtract(X.dot(beta),y)\n",
    "        grad = (X.T.dot(errors))\n",
    "        beta -= (learning_rate/n)*grad\n",
    "        num_iteration+=1\n",
    "        if stop_cond == 'norm_beta':\n",
    "            if (np.linalg.norm(last_beta-beta)<=tol):\n",
    "                break\n",
    "        if stop_cond == 'norm_grad':\n",
    "            if (np.linalg.norm(grad)<=tol):\n",
    "                break\n",
    "        if stop_cond == 'cost':\n",
    "            if (cost(X,y,last_beta)-cost(X,y,beta)<=tol):\n",
    "                break\n",
    "        last_beta= beta.copy()\n",
    "        \n",
    "    return (beta,num_iteration)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tutorial-taste",
   "metadata": {},
   "source": [
    "## Compare between different stopping condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "parliamentary-machine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost stop condition\n",
      "[ 2.25328063e+01 -9.28095335e-01  1.08147935e+00  1.40623117e-01\n",
      "  6.81779327e-01 -2.05666964e+00  2.67428050e+00  1.94234566e-02\n",
      " -3.10406413e+00  2.66151912e+00 -2.07598773e+00 -2.06058073e+00\n",
      "  8.49263523e-01 -3.74360017e+00]\n",
      "963 \n",
      "\n",
      "gradient stop condition\n",
      "[ 2.25328063e+01 -9.28146064e-01  1.08156863e+00  1.40899997e-01\n",
      "  6.81739725e-01 -2.05671827e+00  2.67423017e+00  1.94660717e-02\n",
      " -3.10404426e+00  2.66221764e+00 -2.07678168e+00 -2.06060666e+00\n",
      "  8.49268418e-01 -3.74362713e+00]\n",
      "4081 \n",
      "\n",
      "diffBeta stop condition\n",
      "[ 2.25328063e+01 -9.28146071e-01  1.08156864e+00  1.40900036e-01\n",
      "  6.81739719e-01 -2.05671827e+00  2.67423016e+00  1.94660777e-02\n",
      " -3.10404426e+00  2.66221774e+00 -2.07678180e+00 -2.06060666e+00\n",
      "  8.49268418e-01 -3.74362713e+00]\n",
      "2460 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "(estimated_beta_cost,num_iteration_cost)=gradient_descent(X,y, stop_cond='cost')\n",
    "np.shape(X)\n",
    "print (\"Cost stop condition\")\n",
    "print(estimated_beta_cost)\n",
    "print(num_iteration_cost,'\\n')\n",
    "(estimated_beta_grad,num_iteration_grad)=gradient_descent(X,y, stop_cond='norm_grad')\n",
    "np.shape(X)\n",
    "print (\"gradient stop condition\")\n",
    "print(estimated_beta_grad)\n",
    "print(num_iteration_grad,'\\n')\n",
    "\n",
    "(estimated_beta_diffBeta,num_iteration_diffBeta)=gradient_descent(X,y, stop_cond='norm_beta')\n",
    "np.shape(X)\n",
    "print (\"diffBeta stop condition\")\n",
    "print(estimated_beta_diffBeta)\n",
    "print(num_iteration_diffBeta,'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strategic-relevance",
   "metadata": {},
   "source": [
    "## compare between coef from gradient descent and sklearn model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "environmental-charge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost stop condition\n",
      "[-2.13162821e-14  5.07293325e-05 -8.92817661e-05 -2.76879614e-04\n",
      "  3.96019460e-05  4.86306827e-05  5.03381785e-05 -4.26150333e-05\n",
      " -1.98706430e-05 -6.98527419e-04  7.93957509e-04  2.59250868e-05\n",
      " -4.89428724e-06  2.69565385e-05]\n",
      "gradient stop condition\n",
      "[-2.13162821e-14  1.41042733e-12 -2.48578935e-12 -7.71804842e-12\n",
      "  1.10467191e-12  1.33892897e-12  1.40021328e-12 -1.18572513e-12\n",
      " -5.61328761e-13 -1.94675387e-11  2.21285212e-11  7.18092252e-13\n",
      " -1.35003120e-13  7.47402140e-13]\n",
      "diff beta stop condition\n",
      "[-2.13162821e-14 -7.15481752e-09  1.25991588e-08  3.90928451e-08\n",
      " -5.59304325e-09 -6.79330237e-09 -7.09483894e-09  6.00237567e-09\n",
      "  2.84910051e-09  9.86349300e-08 -1.12141012e-07 -3.64309960e-09\n",
      "  6.94906799e-10 -3.80403886e-09]\n"
     ]
    }
   ],
   "source": [
    "print (\"cost stop condition\") \n",
    "print(estimated_beta_cost-reg_betas)\n",
    "print(\"gradient stop condition\")\n",
    "print(estimated_beta_grad - reg_betas)\n",
    "print ('diff beta stop condition')\n",
    "print(estimated_beta_diffBeta - reg_betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "aerial-contractor",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.size(y)\n",
    "y_mean = (sum(y)/n)*np.ones(np.shape(y))\n",
    "def predict (X,beta):\n",
    "        return X@beta\n",
    "def getSSR (X,y,beta):\n",
    "        return (predict(X,beta)-y_mean).T@(predict(X,beta)-y_mean)\n",
    "def getSST (X,y,beta):\n",
    "        return (y-y_mean).T@(y-y_mean)\n",
    "def getRSquared (X,y,beta):\n",
    "        return getSSR(X,y,beta)/getSST(X,y,beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "pressed-valve",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7406426641092532"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getRSquared(sm.add_constant(X),y,estimated_beta_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "incident-press",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(X, Y, beta):\n",
    "  return ((Y - (X @ beta))**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excited-speech",
   "metadata": {},
   "source": [
    "## standralization of X and calc R^2 using beta estimated from gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "latest-geneva",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7406426641092532"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "getRSquared(sm.add_constant(X),y,estimated_beta_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understanding-ballet",
   "metadata": {},
   "source": [
    "## Plot learning Curves of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "sensitive-radical",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(model, X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1,random_state= 42)\n",
    "        \n",
    "    train_errors , val_errors = [],[]\n",
    "    for i in range (1,len(X_train)):\n",
    "        model.fit(X_train[:i],y_train[:i])\n",
    "        y_train_predict= model.predict(X_train[:i])\n",
    "        y_test_predict = model.predict(X_test)\n",
    "        train_errors.append(mean_squared_error(y_train[:i],y_train_predict))\n",
    "        val_errors.append(mean_squared_error(y_test,y_test_predict))\n",
    "    plt.plot(np.sqrt(train_errors),  label = 'train')\n",
    "    plt.plot(np.sqrt(val_errors), label = \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "descending-train",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_learning_curves(reg,X,y)\n",
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "difficult-speech",
   "metadata": {},
   "source": [
    "## use cross validation to tune lambda parameter for ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "natural-scott",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_alpha (X,y):\n",
    "    cv = KFold(n_splits= 10)\n",
    "    parameters = np.arange(0,200,0.1)\n",
    "    alpha = 0\n",
    "    max_score = sys.maxsize*-1\n",
    "    for par in parameters:\n",
    "        ridge = linear_model.Ridge(alpha = par )\n",
    "        tot_score = 0\n",
    "        for X_train_idx,X_test_idx in cv.split(X):\n",
    "            X_train = X[X_train_idx]\n",
    "            y_train = y[X_train_idx]\n",
    "            X_test =X[X_test_idx]\n",
    "            y_test = y[X_test_idx]\n",
    "            ridge.fit(X_train, y_train)\n",
    "            tot_score += r2_score(y_test,ridge.predict(X_test))\n",
    "         \n",
    "        tot_score/=10\n",
    "        \n",
    "        \n",
    "        if tot_score > max_score:\n",
    "            alpha = par\n",
    "            max_score = tot_score\n",
    "    return alpha        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "union-regular",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112.30000000000001"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = get_alpha(X,y)\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "rental-beauty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r^2 score for linear regression 0.7598135533532475\n",
      "r^2 score for ridge regression 0.76588622025535\n",
      "adj r^2 score for linear regression 0.6754237207476317\n",
      "adj r^2 score for ridge regression 0.6836300273720946\n"
     ]
    }
   ],
   "source": [
    "ridge = linear_model.Ridge(alpha = alpha)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1,random_state=42)\n",
    "linear_reg = linear_model.LinearRegression()\n",
    "ridge.fit(X_train,y_train)\n",
    "linear_reg.fit(X_train,y_train)\n",
    "(n,p) = np.shape(X_test)\n",
    "r_score=r2_score(y_test,ridge.predict(X_test))\n",
    "l_score=r2_score(y_test,linear_reg.predict(X_test))\n",
    "adj_r_score = adjusted_R(r_score,n,p)\n",
    "adj_l_score = adjusted_R(l_score,n,p)\n",
    "print (\"r^2 score for linear regression\",l_score)\n",
    "print(\"r^2 score for ridge regression\",r_score)\n",
    "print (\"adj r^2 score for linear regression\",adj_l_score)\n",
    "print(\"adj r^2 score for ridge regression\",adj_r_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "exact-district",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_learning_curves(ridge,X,y)\n",
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "russian-marketing",
   "metadata": {},
   "source": [
    "## Compare between Coefficients before and after ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "utility-still",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coef fot linear Regression:  [22.532806324110677, -0.9281460643011966, 1.0815686278223822, 0.14089999690428612, 0.6817397247777939, -2.0567182660052157, 2.674230165239318, 0.01946607165704728, -3.104044258086441, 2.662217642473626, -2.0767816838433766, -2.0606066589067593, 0.8492684177053297, -3.7436271264671093]\n",
      "Coef for ridge Regression:  [22.595978892367725, -0.6986156689129943, 0.3961486934815475, -0.42220901819230866, 0.754213784582829, -0.8878258445247157, 2.7191615403286726, -0.11395992884410798, -1.5465144334524263, 0.5732995723447495, -0.5211029589664686, -1.5930461028176979, 0.8116067742021732, -2.9608509287975995]\n",
      "Difference:  [0.06317257 0.2295304  0.68541993 0.56310902 0.07247406 1.16889242\n",
      " 0.04493138 0.133426   1.55752982 2.08891807 1.55567872 0.46756056\n",
      " 0.03766164 0.7827762 ]\n"
     ]
    }
   ],
   "source": [
    "## get coef with ridge regression\n",
    "ridge_beta = []\n",
    "ridge_beta.append(ridge.intercept_)\n",
    "ridge_beta.extend(ridge.coef_)\n",
    "print(\"Coef fot linear Regression: \" ,reg_betas)\n",
    "print(\"Coef for ridge Regression: \" ,ridge_beta)\n",
    "print(\"Difference: \",abs(np.subtract(reg_betas,ridge_beta)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annual-pavilion",
   "metadata": {},
   "source": [
    "## feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "behind-mistake",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[]]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def adjusted_R (r2 , n, p):\n",
    "    return 1-((n-1)*(1-r2)/(n-p-1))\n",
    "\n",
    "r = np.ones((np.size(y),1))\n",
    "my_model = MultipleLinearRegression(r,y)\n",
    "my_model.getRSquared(my_model.getbeta())\n",
    "step_features = []\n",
    "step_features.append([])\n",
    "step_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "american-single",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_step_wise (features,data,y):\n",
    "    lin_reg = linear_model.LinearRegression()\n",
    "    step_features = []\n",
    "    step_features.append([])\n",
    "    curr_features = step_features[0].copy()\n",
    "    p = np.size(features)\n",
    "    for i in range (1,p+1):\n",
    "        taken_feature = ''\n",
    "        max_score = sys.maxsize *-1\n",
    "        for feature in features:\n",
    "            trial_features = curr_features.copy()\n",
    "            trial_features.append(feature)\n",
    "            \n",
    "            lin_reg.fit(data[trial_features],y)\n",
    "            model_score = lin_reg.score(data[trial_features],y)\n",
    "            if model_score > max_score:\n",
    "                max_score = model_score\n",
    "                taken_feature = feature\n",
    "        curr_features.append(taken_feature)\n",
    "        step_features.append(curr_features.copy())\n",
    "        features.remove(taken_feature)\n",
    "    return step_features    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "dimensional-removal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_selections_models = forward_step_wise(features.copy(),boston_data,boston_data.price)\n",
    "\n",
    "feature_selections_models\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "molecular-microphone",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(features,data,y):\n",
    "    m_features = forward_step_wise(features.copy(),data,y)\n",
    "    \n",
    "    train_test_split\n",
    "    max_score = 0\n",
    "    selected_features= []\n",
    "    for i in range(1,len(m_features)):\n",
    "        n = np.size(y)\n",
    "        p = i\n",
    "        curr_features = m_features[i].copy()\n",
    "        X = data[curr_features]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "        lin_model = linear_model.LinearRegression()\n",
    "        lin_model.fit(X_train,y_train)\n",
    "        curr_score = lin_model.score(X_test,y_test)\n",
    "       # curr_adj_score=ad(curr_score,n,p)\n",
    "        if (curr_score>max_score):\n",
    "            max_score = curr_score\n",
    "            selected_features = curr_features.copy()\n",
    "    return selected_features       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "geological-malawi",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LSTAT',\n",
       " 'RM',\n",
       " 'PTRATIO',\n",
       " 'DIS',\n",
       " 'NOX',\n",
       " 'CHAS',\n",
       " 'B',\n",
       " 'ZN',\n",
       " 'CRIM',\n",
       " 'RAD',\n",
       " 'TAX']"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_features(features,boston_data,boston_data.price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "circular-expression",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
